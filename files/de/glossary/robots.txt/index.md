---
title: Robots.txt
slug: Glossary/Robots.txt
l10n:
  sourceCommit: 530c1f54e63834411aa38789b1ac82e3831c4dfa
---

{{GlossarySidebar}}

`Robots.txt` ist eine Datei, die Ã¼blicherweise im Stammverzeichnis einer Website abgelegt wird. Sie entscheidet, ob [Crawlers](/de/docs/Glossary/crawler) Zugriff auf die Website haben oder nicht.

Zum Beispiel kann der Administrator der Seite verbieten, dass Crawlers einen bestimmten Ordner (und alle darin enthaltenen Dateien) besuchen oder eine bestimmte Datei durchsuchen, um zu verhindern, dass diese Dateien von anderen Suchmaschinen indiziert werden.

## Siehe auch

- [Robots.txt](https://en.wikipedia.org/wiki/Robots.txt) auf Wikipedia
- <https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt>
- Standardspezifikation: [RFC9309](https://www.rfc-editor.org/rfc/rfc9309.html)
- <https://www.robotstxt.org/>
