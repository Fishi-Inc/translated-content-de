---
title: Robots.txt
slug: Glossary/Robots.txt
l10n:
  sourceCommit: 530c1f54e63834411aa38789b1ac82e3831c4dfa
---

{{GlossarySidebar}}

Robots.txt ist eine Datei, die normalerweise im Stammverzeichnis einer Website platziert wird. Sie entscheidet, ob {{Glossary("crawler", "Crawler")}} Zugang zur Website gew√§hrt oder verweigert wird.

Zum Beispiel kann der Site-Administrator Crawlern verbieten, einen bestimmten Ordner (und alle darin enthaltenen Dateien) zu besuchen oder eine spezifische Datei zu durchsuchen, um in der Regel zu verhindern, dass diese Dateien von anderen Suchmaschinen indexiert werden.

## Siehe auch

- [Robots.txt](https://en.wikipedia.org/wiki/Robots.txt) auf Wikipedia
- <https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt>
- Standardspezifikation: [RFC9309](https://www.rfc-editor.org/rfc/rfc9309.html)
- <https://www.robotstxt.org/>
